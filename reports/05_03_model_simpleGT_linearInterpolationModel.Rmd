---
title: 'Models: Comparing & Evaluation - Linear Interpolation'
author: "Pier Lorenzo Paracchini"
date: "10 mai 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(knitr)

source("./../scripts/model_evaluation.R")
source("./../scripts/model_supportingFunctions.R")
source("./../scripts/goodTuringSmoothing.R")
source("./../scripts/model_simpleGTS_linearInterpolation.R")


# WINDOWS LOCALE SETTING
Sys.setlocale(category = "LC_ALL",locale = "English_United States.1252")

```

# Testing

A simple approach for testing the different models is to evaluate  __How does our language model prefer good sentences over bad one?__, or in other words __Does the model assign high probability to "real" or "frequently observed" sentences?__.

The test is done using a set of sentences that have not been used for training the model - basic assumption __the model has never seen those sentences__.

The evaluation metrics (ln scale) used to evaluate how well the model is preforming in the __P(S)__ (probability assigned to the sentence S = w1, w2, .., wn) and perplexity. These metrics are related __perplexity = f(probability)__. A better model is the one which assigns a higher probability to the words that actually occurs (reality).

```{r creatingTestDataSetOfSentences}
sentences
```

# Linear Interpolation (simple) with Good-Turing Smoothing

P(wi|wi-1, wi-2) = lambda1 * P(wi|wi-1, wi-2) + lambda2 * P(wi|wi-1) + lambda3 * P(wi)
P models have been implemented using a simple GT smoothing


```{r loadTheModel, cache = T, collapse=T}
load(file = "./../data/processed/04_s01_allCorpora_aggregated_termsFrequency.3g.rdata")
d.3g <- d.ng.df

load(file = "./../data/processed/04_s01_allCorpora_aggregated_termsFrequency.2g.rdata")
d.2g <- d.ng.df

load(file = "./../data/processed/04_s01_allCorpora_aggregated_termsFrequency.1g.rdata")
d.1g <- d.ng.df
d.ng.df <- NULL


#Size of the object in memory
format(object.size(d.3g$terms), "auto")
format(object.size(d.3g$total), "auto")

format(object.size(d.2g$terms), "auto")
format(object.size(d.2g$total), "auto")

format(object.size(d.1g$terms), "auto")
format(object.size(d.1g$total), "auto")

```


```{r testLinearInterpolation, collapse = T}

m4.l1 = 0.9; m4.l2 = 0.09; m4.l3 = 0.01
model4.evaluation <- sapply(sentences, FUN = estimateSentProb.linearInterpolation.model.withGoodTuring.smoothing, 
                            t.terms = d.3g$terms, t.counters = d.3g$total,
                            b.terms = d.2g$terms, b.counters = d.2g$total,
                            u.terms = d.1g$terms, u.counters = d.1g$total,
                            lambda_1 = m4.l1, lambda_2 = m4.l2, lambda_3 = m4.l3)

colnames(model4.evaluation) <- NULL
model4.evaluation <- t(model4.evaluation)
model4.perplexity <- calculatePerplexity(model4.evaluation)
```

`r kable(model4.evaluation, caption = "Linear Interpolation Model - Base")`

__Perplexity (log base2):__ `r model4.perplexity`


```{r testLinearInterpolation_1, collapse = T}

m5.l1 = 0.8; m5.l2 = 0.15; m5.l3 = 0.05
model5.evaluation <- sapply(sentences, FUN = estimateSentProb.linearInterpolation.model.withGoodTuring.smoothing, 
                            t.terms = d.3g$terms, t.counters = d.3g$total,
                            b.terms = d.2g$terms, b.counters = d.2g$total,
                            u.terms = d.1g$terms, u.counters = d.1g$total,
                            lambda_1 = m5.l1, lambda_2 = m5.l2, lambda_3 = m5.l3)

colnames(model5.evaluation) <- NULL
model5.evaluation <- t(model5.evaluation)
model5.perplexity <- calculatePerplexity(model5.evaluation)
```

```{r testLinearInterpolation_2, collapse = T}

m6.l1 = 0.6; m6.l2 = 0.3; m6.l3 = 0.1
model6.evaluation <- sapply(sentences, FUN = estimateSentProb.linearInterpolation.model.withGoodTuring.smoothing, 
                            t.terms = d.3g$terms, t.counters = d.3g$total,
                            b.terms = d.2g$terms, b.counters = d.2g$total,
                            u.terms = d.1g$terms, u.counters = d.1g$total,
                            lambda_1 = m6.l1, lambda_2 = m6.l2, lambda_3 = m6.l3)

colnames(model6.evaluation) <- NULL
model6.evaluation <- t(model6.evaluation)
model6.perplexity <- calculatePerplexity(model6.evaluation)
```

```{r testLinearInterpolation_3, collapse = T}

m7.l1 = 0.5; m7.l2 = 0.4; m7.l3 = 0.1
model7.evaluation <- sapply(sentences, FUN = estimateSentProb.linearInterpolation.model.withGoodTuring.smoothing, 
                            t.terms = d.3g$terms, t.counters = d.3g$total,
                            b.terms = d.2g$terms, b.counters = d.2g$total,
                            u.terms = d.1g$terms, u.counters = d.1g$total,
                            lambda_1 = m7.l1, lambda_2 = m7.l2, lambda_3 = m7.l3)

colnames(model7.evaluation) <- NULL
model7.evaluation <- t(model7.evaluation)
model7.perplexity <- calculatePerplexity(model7.evaluation)
```

`r kable(model7.evaluation, caption = "Linear Interpolation Model - Base")`

__Perplexity (log base2):__ `r model7.perplexity`


```{r testLinearInterpolation_4, collapse = T}

m8.l1 = 0.4; m8.l2 = 0.4; m8.l3 = 0.2
model8.evaluation <- sapply(sentences, FUN = estimateSentProb.linearInterpolation.model.withGoodTuring.smoothing, 
                            t.terms = d.3g$terms, t.counters = d.3g$total,
                            b.terms = d.2g$terms, b.counters = d.2g$total,
                            u.terms = d.1g$terms, u.counters = d.1g$total,
                            lambda_1 = m8.l1, lambda_2 = m8.l2, lambda_3 = m8.l3)

colnames(model8.evaluation) <- NULL
model8.evaluation <- t(model8.evaluation)
model8.perplexity <- calculatePerplexity(model8.evaluation)
```

`r kable(model8.evaluation, caption = "Linear Interpolation Model - Base")`

__Perplexity (log base2):__ `r model8.perplexity`

```{r testLinearInterpolation_5, collapse = T}

m9.l1 = 0.4; m9.l2 = 0.3; m9.l3 = 0.3
model9.evaluation <- sapply(sentences, FUN = estimateSentProb.linearInterpolation.model.withGoodTuring.smoothing, 
                            t.terms = d.3g$terms, t.counters = d.3g$total,
                            b.terms = d.2g$terms, b.counters = d.2g$total,
                            u.terms = d.1g$terms, u.counters = d.1g$total,
                            lambda_1 = m9.l1, lambda_2 = m9.l2, lambda_3 = m9.l3)

colnames(model9.evaluation) <- NULL
model9.evaluation <- t(model9.evaluation)
model9.perplexity <- calculatePerplexity(model9.evaluation)
```

`r kable(model9.evaluation, caption = "Linear Interpolation Model - Base")`

__Perplexity (log base2):__ `r model9.perplexity`


Model | lambda1 | lambda2 | lambda3 |Perplexity
------------- | -------------| -------------| -------------| -------------
LI - GT smoothing| `r m4.l1` | `r m4.l2` | `r m4.l3` |`r model4.perplexity`
LI - GT smoothing| `r m5.l1` | `r m5.l2` | `r m5.l3` |`r model5.perplexity`
LI - GT smoothing| `r m6.l1` | `r m6.l2` | `r m6.l3` |`r model6.perplexity`
LI - GT smoothing| `r m7.l1` | `r m7.l2` | `r m7.l3` |`r model7.perplexity`
LI - GT smoothing| `r m8.l1` | `r m8.l2` | `r m8.l3` |`r model8.perplexity`
LI - GT smoothing| `r m9.l1` | `r m9.l2` | `r m9.l3` |`r model9.perplexity`