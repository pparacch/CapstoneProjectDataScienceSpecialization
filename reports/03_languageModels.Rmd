---
title: "Language Models"
author: "Pier Lorenzo Paracchini"
date: "1 mai 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# WINDOWS LOCALE SETTING
Sys.setlocale(category = "LC_ALL",locale = "English_United States.1252")
```

## Language Modeld Notes & Playgrounds

See 04_languageModels.Rmd for actual implementation.

```{r unigramModel, collapse = T}
# rm(list = ls())
source("./../scripts/model.R")

require(profr)

Rprof(tmp <- tempfile())
twitter.1g.list <- load.twitter.1g.data("./../data/processed/02_01_s05_sampleCorpus_twitter_termsfrequency.1g.Rdata",
                                        "./../data/processed/02_01_s04_sampleCorpus_twitter_tdm.1g.Rdata")
u.terms <- rownames(twitter.1g.list$tcv)
u.counters <- twitter.1g.list$tcv$freq
u.N <- sum(u.counters)
Rprof(NULL)
summaryRprof(tmp)


format(object.size(u.terms), "auto")
format(object.size(u.counters), "auto")
format(object.size(twitter.1g.list$tcv), "auto")

unigramModel.probabilityForWord <- function(word){
    print("--- UNIGRAM-Model ---")
    
    idx <- which(u.terms == word)
    print(paste("Term:", word))
    if(length(idx) != 0){
        print(paste("  idx:", idx))
        print(paste("  count:", u.counters[idx]))
        print(paste("  N:", u.N))
        print(paste("  probability:", 100 * (u.counters[which(u.terms == word)]/ u.N), "%"))
    }else{
        print("    Not Found")
    }
    
    print("---------------------")
}



Rprof(tmp <- tempfile())
unigramModel.probabilityForWord("<s>")
Rprof(NULL)
summaryRprof(tmp)


Rprof(tmp <- tempfile())
unigramModel.probabilityForWord("i'm")
Rprof(NULL)
summaryRprof(tmp)

Rprof(tmp <- tempfile())
unigramModel.probabilityForWord("sentimental")
Rprof(NULL)
summaryRprof(tmp)

Rprof(tmp <- tempfile())
unigramModel.probabilityForWord("ciaooo")
Rprof(NULL)
summaryRprof(tmp)

```

```{r biGramsModel, collapse = T}
# source("./../scripts/model.R")

Rprof(tmp <- tempfile())
twitter.2g.list <- load.twitter.2g.data("./../data/processed/02_01_s05_sampleCorpus_twitter_termsfrequency.2g.Rdata",
                                        "./../data/processed/02_01_s04_sampleCorpus_twitter_tdm.2g.Rdata")
b.terms <- rownames(twitter.2g.list$tcv)
b.counters <- twitter.2g.list$tcv$freq
b.N <- sum(b.counters)
b.V <- length(unique(b.terms))
Rprof(NULL)
summaryRprof(tmp)


format(object.size(b.terms), "auto")
format(object.size(b.counters), "auto")
format(object.size(twitter.2g.list$tcv), "auto")

unigramModel.counterForTerm <- function(word){
    idx <- which(u.terms == word)
    print(paste("      Term:", word))
    if(length(idx) != 0){
        print(paste("        idx:", idx))
        print(paste("        count:", u.counters[idx]))
        print(paste("        N:", u.N))
        u.counters[idx]
    }else{
        print("        Not Found")
        0
    }
}

bigramsModel.probabilityFor <- function(word.i.minus.1, word.i){
    print("---  BIGRAM-Model ---")
    
    term <- paste(word.i.minus.1, word.i)
    idx <- which(b.terms == term)
    
    print(paste("Term:", term))
    print(paste("  Words: (i) '", word.i, ", (i-1)'", word.i.minus.1, "'", sep = ""))
    
    if(length(idx) != 0){
        w.previous <- word.i.minus.1
        w.previous.count <- unigramModel.counterForTerm(w.previous)
        
        print(paste("  idx:", idx))
        print(paste("  count:", b.counters[idx]))
        print(paste("  wi-1:", w.previous))
        print(paste("  count wi-1:", w.previous.count))
        print(paste("  probability:",100 * (b.counters[which(b.terms == term)]/ w.previous.count), "%"))
    }else{
        print("  Not Found")
    }
    
    print("---------------------")
}


Rprof(tmp <- tempfile())
ngramTokenize("<s> i'm", ng = 1)
Rprof(NULL)
summaryRprof(tmp)

Rprof(tmp <- tempfile())
unigramModel.counterForTerm("<s>")
Rprof(NULL)
summaryRprof(tmp)

Rprof(tmp <- tempfile())
bigramsModel.probabilityFor("<s>", "i'm")
Rprof(NULL)
summaryRprof(tmp)

bigramsModel.probabilityFor("for", "the")
```

```{r triGramsModel, collapse = T}
#source("./../scripts/model.R")

Rprof(tmp <- tempfile())
twitter.3g.list <- load.twitter.3g.data("./../data/processed/02_01_s05_sampleCorpus_twitter_termsfrequency.3g.Rdata",
                                        "./../data/processed/02_01_s04_sampleCorpus_twitter_tdm.3g.Rdata")
t.terms <- rownames(twitter.3g.list$tcv)
t.counters <- twitter.3g.list$tcv$freq
t.N <- sum(t.counters)
t.V <- length(unique(t.terms))
Rprof(NULL)
summaryRprof(tmp)


format(object.size(t.terms), "auto")
format(object.size(t.counters), "auto")
format(object.size(twitter.3g.list$tcv), "auto")

bigramModel.counterForTerm <- function(word){
    idx <- which(b.terms == word)
    # print(paste("      Term:", word))
    if(length(idx) != 0){
        # print(paste("        idx:", idx))
        # print(paste("        count:", b.counters[idx]))
        # print(paste("        N:", b.N))
        b.counters[idx]
    }else{
        stop("bigramModel.counterForTerm", word, "not found")
    }
}

trigramsModel.probabilityFor <- function(word.i.minus.2, word.i.minus.1, word.i){
    #print("---  TRIGRAM-Model ---")
    term <- paste(word.i.minus.2, word.i.minus.1, word.i)
    idx <- which(t.terms == term)
    probability <- -1
    
    #print(paste("Term:", term))

    if(length(idx) != 0){
        w.previous.bigram <- paste(word.i.minus.2, word.i.minus.1)
        w.previous.bigram.count <- bigramModel.counterForTerm(w.previous.bigram)
        
        #print(paste("  idx:", idx))
        #print(paste("  count:", t.counters[idx]))
        #print(paste("  wi-1:", w.previous.bigram))
        #print(paste("  count wi-1:", w.previous.bigram.count))
        probability <- (t.counters[which(t.terms == term)]/ w.previous.bigram.count)
        #print(paste("  probability:",100 * probability, "%"))
    }else{
        stop("trigramsModel.probabilityFor", term, "not found")
    }
    
    #print("----------------------")
    probability
}

Rprof(tmp <- tempfile())
trigramsModel.probabilityFor("<s>", "thanks", "for")
Rprof(NULL)
summaryRprof(tmp)

trigramsModel.probabilityFor("i", "love", "you")
```


## Investigating the usage of hash table to store the language models


```{r hashTableInvestigate}
require(profr)

data <- rnorm(1E6)
data_ls <- as.list(data)
names(data_ls) <- paste("V", c(1:1E6), sep="")
format(object.size(data_ls), "auto")


index_rand <- sample(1:1E6, size=1000, replace=T)
index <- paste("V", index_rand, sep="")

Rprof(tmp <- tempfile())
list_found <- sapply(index, FUN=function(x){data_ls[[x]]})
Rprof(NULL)
summaryRprof(tmp)

library(hash)
data_h <- hash(names(data_ls), data)
format(object.size(data_h), "auto")

Rprof(tmp <- tempfile())
hash_found <- sapply(index, FUN=function(x){data_h[[x]]})
Rprof(NULL)
summaryRprof(tmp)
```

## Trigrams


```{r TrigramsInvestigate, eval = F}

require(profr)
require(hash)


#Order trigrams in decrescent order
idx <- order(t.counters, decreasing = T)
t.counters <- t.counters[idx]
t.terms <- t.terms[idx]
t.N <- sum(t.counters)
t.V <- length(unique(t.terms))

#Lets limit the trigrams to the ones with at least 3 occurences - the other are filtered out
#50000 can be still a significant number (Note to self)

sum(t.counters >= 3) #circa 50000

t.counters.atLeast <- (t.counters >= 3)
t.terms <- t.terms[t.counters.atLeast]
t.counters <- t.counters[t.counters.atLeast]
t.N <- sum(t.counters)
t.V <- length(unique(t.terms))

size <- length(t.terms)

data.bigrams <- character(size)
data.nextWord <- character(size)
data.prob <- integer(size)


getTrigramModel.forTrigram <- function(i){
    elem <- t.terms[i]
    elem.1grams <- ngramTokenize(y = elem, ng = 1)
    elem.bigram <- paste(elem.1grams[1], elem.1grams[2])
    elem.nextWord <- elem.1grams[3]
    elem.prob <- trigramsModel.probabilityFor(elem.1grams[1], elem.1grams[2], elem.1grams[3])
    
    # print(elem.bigram)
    # print(elem.nextWord)
    # print(elem.prob)
    
    data.bigrams[i] <<- elem.bigram
    data.nextWord[i] <<- elem.nextWord
    data.prob[i] <<- elem.prob
}

getTrigramModel.forTrigram(1)
getTrigramModel.forTrigram(2)
getTrigramModel.forTrigram(3)


##TIME CONSUMING but BETTER THAN THE ONE BELOW
##NEED TO BE OPTIMIZED
Rprof(tmpf <- tempfile())
tmp <- sapply(c(1:size), FUN = getTrigramModel.forTrigram)
Rprof(NULL)
summaryRprof(tmpf)


#CRAPPY CODE - NOT VERY PERFORMANT
# for(i in 1:size){
#     if(i %% 1000 == 0) print(paste("Processing", i, "of", size))
#     getTrigramModel.forTrigram(i)
# }


save(t.terms, t.counters, t.N, t.V, data.bigrams, data.nextWord, data.prob, 
     file = "./../data/processed/03_languageModel.playground.twitter.trigrams.Rdata")

format(object.size(data.bigrams), "auto")
format(object.size(data.nextWord), "auto")
format(object.size(data.prob), "auto")

```

```{r useModel}
rm(list = ls())
load(file = "./../data/processed/03_languageModel.playground.twitter.trigrams.Rdata")

#Case 1
# The guy in front of me just bought a pound of bacon, a bouquet, and a case of
index <- which(data.bigrams == "case of")
data.nextWord[index]
data.prob[index]

#Case 2
#You're the reason why I smile everyday. Can you follow me please? It would mean the
index <- which(data.bigrams == "mean the")
data.nextWord[index]
data.prob[index]

#Case 3
# Hey sunshine, can you follow me and make me the
index <- which(data.bigrams == "me the")
data.nextWord[index]
data.prob[index]

#Case 4
# Very early observations on the Bills game: Offense still struggling but the
index <- which(data.bigrams == "but the")
data.nextWord[index]
data.prob[index]

#Case 5
# Go on a romantic date at the
index <- which(data.bigrams == "at the")
data.nextWord[index]
data.prob[index]
data.nextWord[index][order(data.prob[index], decreasing = T)]

```

