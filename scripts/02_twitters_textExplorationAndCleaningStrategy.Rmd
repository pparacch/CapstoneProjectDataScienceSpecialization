---
title: "Twitters - Text Exploration"
author: "Pier Lorenzo Paracchini"
date: "23 April 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# MAC OS 
#library(doMC)
#registerDoMC(cores = 4)

#View the locale encoding
getOption("encoding")
Sys.getlocale("LC_CTYPE")
localeToCharset()

# WINDOWS LOCALE SETTING
Sys.setlocale(category = "LC_ALL",locale = "English_United States.1252")

getOption("encoding")
Sys.getlocale("LC_CTYPE")
localeToCharset()
```

```{r supportingFunctions, echo = F}
normalizeLowerLetter <- function(texts, replaceWith = ""){
    gsub(pattern = "[a-z]{1,}", replacement = replaceWith, x = texts)
}

normalizeCapitalLetter <- function(texts, replaceWith = ""){
    gsub(pattern = "[A-Z]", replacement = replaceWith, x = texts)
}

normalizeDigits <- function(texts, replaceWith = ""){
    gsub(pattern = "[0-9]", replacement = replaceWith, x = texts)
}

normalizePunctuation <- function(texts, replaceWith = ""){
    gsub(pattern = "[[:punct:]]", replacement = replaceWith, x = texts)
}

normalizeSpaces <- function(texts, replaceWith = ""){
    gsub(pattern = "[[:space:]]+", replacement = replaceWith, x = texts)
}

findContractions <- function(aText){
    # a <- regexpr("[a-z]* ?'[a-z]*", aText, perl=TRUE, ignore.case = T)
    a <- regexpr("[a-z]* ?'[a-z]* ?[a-z]*", aText, perl=TRUE, ignore.case = T)
    regmatches(aText,a)
}

replaceContraction <- function(texts, contraction, replaceWith, ignoreCase = F){
    gsub(pattern = contraction, replacement = replaceWith, x = texts, ignore.case = ignoreCase)
}

test.u <- "I'm coo... Jus at work hella tired are u ever in cali"
test.u.expected <- "I'm coo... Jus at work hella tired are you ever in cali"
test.u.expected == replaceContraction(texts = test.u, contraction = " u ", replaceWith = " you ", ignoreCase = T)

test.r <- "I'm coo... Jus at work hella tired r you ever in cali"
test.r.expected <- "I'm coo... Jus at work hella tired are you ever in cali"
test.r.expected == replaceContraction(texts = test.r, contraction = " r ", replaceWith = " are ", ignoreCase = T)

removeRT_retweetted <- function(texts, ignoreCase = T){
    a <- gsub(pattern = " RT :? ?", replacement = " ", x = texts, ignore.case = ignoreCase)
    gsub(pattern = "^RT ", replacement = "", x = a, ignore.case = ignoreCase)
}

test.RT <- c("I'm cool... RT : Just at work RT tired r you ever in cali", "RT I'm cool...")
test.RT.expected <- c("I'm cool... Just at work tired r you ever in cali", "I'm cool...")
result <- removeRT_retweetted(test.RT)
test.RT.expected[1] == result[1]
test.RT.expected[2] == result[2]

```


## Twitter Data - Text Exploration
TOTHINK Do I need to split the datasets? Applicable for all of the others
TODO How many tweets are into the dataset?

```{r loadTwitterData, echo = F, cache = T}
con <- file("./../data/original/final/en_US/en_US.twitter.txt", "r") 
data.twitter.all.ori <- readLines(con, skipNul = T)
close(con)

data.twitter.all <- data.twitter.all.ori #Optional


#For an easy visual inspection
data.twitter.all.df <- as.data.frame(data.twitter.all)
```

Let's start to see which are the characters used in the tweets if some interesting patterns are found

```{r twitterTextExplorations}
tmp <- normalizeLowerLetter(texts = data.twitter.all, replaceWith = "a")
data.twitter.all.df$normalizedLower <- tmp
head(tmp, 20)

#Same patterns with Capital letters 
# RT, DC (Washington DC)
data.twitter.all[1]

# a'a -> you'll know, don't, they've, I'm
data.twitter.all[2]
data.twitter.all[3]

## more details on contractions
contractions <- Reduce(c,lapply(data.twitter.all[1:30000], findContractions))
head(sort(table(contractions), decreasing = T), 20)

# usage of r (are) u (you), and an example of mispelling coo ... instead of cool
data.twitter.all[8]

# THIS, THIS WEEK, BILLION - safe to normalize to lower letter
data.twitter.all[7]
data.twitter.all[10]
data.twitter.all[20]

# "RT :" (as re-tweeted) - add to the list of stopwords
data.twitter.all[20]
data.twitter.all[length(data.twitter.all) - 3]

# hastags like #MothersDay or @something
# TODO should be removed
data.twitter.all[20]


#Lets find some unexpected characters not alphanum, space, punctuation
tmp <- normalizeLowerLetter(texts = data.twitter.all, replaceWith = "")
data.twitter.all.df$removedLower <- tmp
tmp <- normalizeCapitalLetter(texts = tmp, replaceWith = "")
data.twitter.all.df$removedCapital <- tmp
tmp <- normalizeDigits(texts = tmp, replaceWith = "")
data.twitter.all.df$removedDigits <- tmp
tmp <- normalizePunctuation(texts = tmp, replaceWith = "")
data.twitter.all.df$removedPunctuation <- tmp
tmp <- normalizeSpaces(texts = tmp, replaceWith = "")
data.twitter.all.df$removedSpaces <- tmp
data.twitter.all.df$nchar <- nchar(data.twitter.all.df$removedSpaces)

special <- data.twitter.all.df[data.twitter.all.df$nchar > 0,]
```

#### Contractions

    'A contraction is a shortened form of one or two words (one of which is usually a verb). In a contraction, an apostrophe takes the place of the missing letter or letters. Some contractions are: I'm (I am), can't (cannot), how's (how is), and Ma'am (Madam). For example, "don't" is a contraction that is short for "do not"; the apostrophe in "don't" takes the place of the missing "o". Another example is "o'clock," a contraction "of the clock." A less common example of a contraction is "jack-o'-lantern," short for "jack-of-lantern"; in it, the apostrophe takes the place of the missing "f" in "of."'

__Strategy__: replace contraction with the full form (only for unambiguous cases) 
Note More complex cases like _I'd_ where the full form could be _I would or I had_ have not been considered.

```{r twitterContractionsRemoval}
contractions <- Reduce(c,lapply(data.twitter.all[1:20000], findContractions))
head(sort(table(contractions), decreasing = T), 20)

##Contractions Replacement
##Note I'd, ain't not easy to replace, replacement is connected to the sentence and context
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "haven't", replaceWith = "have not",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "hasn't", replaceWith = "has not",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "hadn't", replaceWith = "had not",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "I've", replaceWith = "I have",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "you've", replaceWith = "you have",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "we've", replaceWith = "we have",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "they've", replaceWith = "they have",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "isn't", replaceWith = "is not",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "aren't", replaceWith = "are not",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "wasn't", replaceWith = "was not",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "weren't", replaceWith = "were not",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "i'm", replaceWith = "I am",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "you're", replaceWith = "you are",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "he's", replaceWith = "he is",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "it's", replaceWith = "it is",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "we're", replaceWith = "we are",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "they're", replaceWith = "they are",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "don't", replaceWith = "do not",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "doesn't", replaceWith = "does not",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "didn't", replaceWith = "did not",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "can't", replaceWith = "can not",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "wouldn't", replaceWith = "would not",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "would've", replaceWith = "would have",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "shouldn't", replaceWith = "should not",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "should've", replaceWith = "should have",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "couldn't", replaceWith = "could not",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "could've", replaceWith = "could have",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "won't", replaceWith = "will not",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "I'll", replaceWith = "I will",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "you'll", replaceWith = "you will",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "he'll", replaceWith = "he will",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "she'll", replaceWith = "she will",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "it'll", replaceWith = "it will",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "we'll", replaceWith = "we will",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "they'll", replaceWith = "they will",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "that'll", replaceWith = "that will",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "that's", replaceWith = "that is",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "what's", replaceWith = "what is",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "let's", replaceWith = "let us",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "there's", replaceWith = "there is",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "here's", replaceWith = "here is",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "who's", replaceWith = "who is",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "where's", replaceWith = "where is",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "how's", replaceWith = "how is",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "c'mon", replaceWith = "come on",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "doin'", replaceWith = "doing",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "y'all", replaceWith = "you all",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "[yY]a?'a?ll", replaceWith = "you all",ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "ma'am", replaceWith = "madam",ignoreCase = T)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = " u ", replaceWith = " you ", ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = " r ", replaceWith = " are ", ignoreCase = T)

contractions.sample <- Reduce(c,lapply(data.twitter.all[1:100000], findContractions))
head(sort(table(contractions.sample), decreasing = T), 30)

data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "'d be ", replaceWith = " would be", ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "'d like ", replaceWith = " would like", ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "'d love ", replaceWith = " would love", ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "'d rather ", replaceWith = " would rather", ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "'d say ", replaceWith = " would say", ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "'d have ", replaceWith = " would have", ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "'d make ", replaceWith = " would make", ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "'d think ", replaceWith = " would think", ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "'d go ", replaceWith = " would go", ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "'d get ", replaceWith = " would get", ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "'d do ", replaceWith = " would do", ignoreCase = T)
data.twitter.all <- replaceContraction(texts = data.twitter.all, contraction = "'d give ", replaceWith = " would give", ignoreCase = T)


contractions.sample <- Reduce(c,lapply(data.twitter.all[1:300000], findContractions))
head(sort(table(contractions.sample), decreasing = T), 30)

```

### Remove RT (retweet)

```{r removeRT_retweet}
data.twitter.all <- removeRT_retweetted(data.twitter.all)
```

### Remove hashtags



### Unconventional Tweets & Profanity Words

```{r someDirtyInvestigation}
twitters.g1Spam <- grepl("WET TSHIRT", data.twitter.all, ignore.case = F)
head(data.twitter.all[twitters.g1Spam],3)

## These could be safely remove from the tweets
data.twitter.all <- data.twitter.all[!twitters.g1Spam]

twitters.g1Spam <- grepl("WET TSHIRT", data.twitter.all, ignore.case = F)
head(data.twitter.all[twitters.g1Spam],3)

## Look for any word based on "sex" .. 
twitters.sex <- grepl("[[:space:]]sex[a-z]*[[:space:]]", data.twitter.all, ignore.case = T)
banned.sex <- as.data.frame(data.twitter.all[twitters.sex])

twitters.ass <- grepl("[[:space:]]ass[a-z]*[[:space:]]", data.twitter.all, ignore.case = T)
banned.ass <- as.data.frame(data.twitter.all[twitters.ass])
```

__Strategy__ -> profanity words will be removed from the tweeters (as stopwords)
Using external resource http://www.cs.cmu.edu/~biglou/resources/

```{r loadBasWordsList, echo = F, cache = T}
con <- file("./bad-words.txt", "r") 
stopwords.badWords <- readLines(con, skipNul = T)
close(con)

head(stopwords.badWords)
tail(stopwords.badWords)
```

### Remove Special Characters due to Encoding

__Strategy__ -> limit the set of available characters to alphanumeric, punctuation and spaces

```{r removeSpecialCharacters}
# data.twitter.all.simple <- gsub(pattern = "[^[:alnum:]^[:space:]^[:punct:]]", replacement = "", x = data.twitter.all)
#data.twitter.all.simple <- gsub(pattern = "[^a-zA-Z0-9[:space:]]", replacement = " ", x = data.twitter.all)
data.twitter.all.simple <-  iconv(data.twitter.all, from = localeToCharset(), to = "ASCII", "")

data.twitter.all[7036:7066]
data.twitter.all.simple[7036:7066]

save(data.twitter.all.ori, data.twitter.all, data.twitter.all.simple, file = "./../data/processed/twitter.datasets.Rdata")
```

```{r ngrams}
require(tm)
require(wordcloud)
require(RWeka)

tdm.generate <- function(string, ng){
  corpus <- Corpus(VectorSource(string))
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removeWords, stopwords.badWords)
  corpus <- tm_map(corpus, removeNumbers) 
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, stripWhitespace)
  # MAC OS Manadtory if not using doMC library
  #options(mc.cores=1) 
  # http://stackoverflow.com/questions/17703553/bigrams-instead-of-single-words-in-termdocument-matrix-using-r-and-rweka/20251039#20251039
  BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = ng, max = ng)) # create n-grams
  tdm <- TermDocumentMatrix(corpus, control = list(tokenize = BigramTokenizer)) # create tdm from n-grams
  tdm
}

tdm.1g <- tdm.generate(data.twitter.all.simple[1:20000], 1)
findFreqTerms(tdm.1g, 40)
findFreqTerms(tdm.1g, 60)
findFreqTerms(tdm.1g, 80)
findFreqTerms(tdm.1g, 100)

tdm89.1g <- removeSparseTerms(tdm.1g, 0.89)
tdm9.1g  <- removeSparseTerms(tdm.1g, 0.9)
tdm91.1g <- removeSparseTerms(tdm.1g, 0.91)
tdm99.1g <- removeSparseTerms(tdm.1g, 0.99)

notsparse <- tdm99.1g
m = as.matrix(notsparse)
v = sort(rowSums(m),decreasing=TRUE)
d.1g = data.frame(word = names(v),freq=v)
 
# Create the word cloud
pal = brewer.pal(9,"BuPu")
wordcloud(words = d.1g$word,
          freq = d.1g$freq,
          #scale = c(3,.8),
          random.order = F,
          colors = pal)

tdm.2g <- tdm.generate(data.twitter.all.simple[1:10000], 2)
findFreqTerms(tdm.2g, 40)
findFreqTerms(tdm.2g, 60)
findFreqTerms(tdm.2g, 80)
findFreqTerms(tdm.2g, 100)

tdm89.2g <- removeSparseTerms(tdm.2g, 0.89)
tdm9.2g  <- removeSparseTerms(tdm.2g, 0.9)
tdm91.2g <- removeSparseTerms(tdm.2g, 0.91)
tdm99.2g <- removeSparseTerms(tdm.2g, 0.99)

notsparse <- tdm99.2g
m = as.matrix(notsparse)
v = sort(rowSums(m),decreasing=TRUE)
d.2g = data.frame(word = names(v),freq=v)
 
# Create the word cloud
pal = brewer.pal(9,"BuPu")
wordcloud(words = d.2g$word,
          freq = d.2g$freq,
          scale = c(3,.8),
          random.order = F,
          colors = pal)


tdm.3g <- tdm.generate(data.twitter.all.simple[1:10000], 3)
findFreqTerms(tdm.3g, 40)
findFreqTerms(tdm.3g, 60)
findFreqTerms(tdm.3g, 80)
findFreqTerms(tdm.3g, 100)

tdm89.3g <- removeSparseTerms(tdm.3g, 0.89)
tdm9.3g  <- removeSparseTerms(tdm.3g, 0.9)
tdm91.3g <- removeSparseTerms(tdm.3g, 0.91)
tdm99.3g <- removeSparseTerms(tdm.3g, 0.998)

notsparse <- tdm99.3g
m = as.matrix(notsparse)
v = sort(rowSums(m),decreasing=TRUE)
d.3g = data.frame(word = names(v),freq=v)
 
# Create the word cloud
pal = brewer.pal(9,"BuPu")
wordcloud(words = d.3g$word,
          freq = d.3g$freq,
          scale = c(3,.8),
          random.order = F,
          colors = pal)

```

