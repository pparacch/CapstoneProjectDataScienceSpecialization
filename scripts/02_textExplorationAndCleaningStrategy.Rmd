---
title: "Text Exploration"
author: "Pier Lorenzo Paracchini"
date: "23 April 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r supportingFunctions, echo = F}
normalizeLowerLetter <- function(texts, replaceWith = ""){
    gsub(pattern = "[a-z]{1,}", replacement = replaceWith, x = texts)
}

normalizeCapitalLetter <- function(texts, replaceWith = ""){
    gsub(pattern = "[A-Z]", replacement = replaceWith, x = texts)
}

normalizeDigits <- function(texts, replaceWith = ""){
    gsub(pattern = "[0-9]", replacement = replaceWith, x = texts)
}

normalizePunctuation <- function(texts, replaceWith = ""){
    gsub(pattern = "[[:punct:]]", replacement = replaceWith, x = texts)
}

normalizeSpaces <- function(texts, replaceWith = ""){
    gsub(pattern = "[[:space:]]", replacement = replaceWith, x = texts)
}

```


```{r someInfo, collapse = T}
#View the locale encoding
getOption("encoding")
Sys.getlocale("LC_CTYPE")

#Same info
localeToCharset()
```


## Twitter Data Text Exploration

```{r loadTwitterData, echo = F, cache = T}
con <- file("./../data/original/final/en_US/en_US.twitter.txt", "r") 
data.twitter.all <- readLines(con, skipNul = T)
close(con)

#For an easy visual inspection
data.twitter.all.df <- as.data.frame(data.twitter.all)
```

Let's start to see which are the characters used in the tweets if some interesting pattaer are found

### Text Investigation
```{r twitterTextExplorations}
tmp <- normalizeLowerLetter(texts = data.twitter.all, replaceWith = "a")
data.twitter.all.df$normalizedLower <- tmp
head(tmp, 20)

#Same patterns with Capital letters 
# RT, DC (Washington DC)
data.twitter.all[1]

# a'a -> you'll know, don't, they've, I'm
data.twitter.all[2]
data.twitter.all[3]

# usage of r (are) u (you), and an example of mispelling coo ... instead of cool
data.twitter.all[8]

# THIS, THIS WEEK, BILLION - safe to normalize to lower letter
data.twitter.all[7]
data.twitter.all[10]
data.twitter.all[20]

# "RT :"" (as re-tweeted)
data.twitter.all[20]
data.twitter.all[length(data.twitter.all) - 3]

# hastags like #MothersDay
# TODO hashtags should be removed
data.twitter.all[20]


#Lets find some unexpected characters not alphanum, space, punctuation

tmp <- normalizeLowerLetter(texts = data.twitter.all, replaceWith = "")
data.twitter.all.df$removedLower <- tmp
tmp <- normalizeCapitalLetter(texts = tmp, replaceWith = "")
data.twitter.all.df$removedCapital <- tmp
tmp <- normalizeDigits(texts = tmp, replaceWith = "")
data.twitter.all.df$removedDigits <- tmp
tmp <- normalizePunctuation(texts = tmp, replaceWith = "")
data.twitter.all.df$removedPunctuation <- tmp
tmp <- normalizeSpaces(texts = tmp, replaceWith = "")
data.twitter.all.df$removedSpaces <- tmp
data.twitter.all.df$nchar <- nchar(data.twitter.all.df$removedSpaces)

special <- data.twitter.all.df[data.twitter.all.df$nchar > 0,]

```
### Unconventional Tweets

```{r someDirtyInvestigation}
twitters.g1Spam <- grepl("WET TSHIRT", data.twitter.all, ignore.case = F)
banned.g1Spam <- as.data.frame(data.twitter.all[twitters.g1Spam])
head(banned.g1Spam)
## These could be safely remove from the tweets

## Look for any word based on "sex" .. 
twitters.sex <- grepl("[[:space:]]sex[a-z]*[[:space:]]", data.twitter.all, ignore.case = T)
banned.sex <- as.data.frame(data.twitter.all[twitters.sex])


```

